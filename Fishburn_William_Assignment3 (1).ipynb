{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting training set images...\n",
      "X_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               4194816   \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 4,200,842\n",
      "Trainable params: 4,200,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "40000/40000 [==============================] - 48s 1ms/step - loss: 1.7881 - accuracy: 0.3783 - val_loss: 1.5025 - val_accuracy: 0.4739\n",
      "Epoch 2/20\n",
      "40000/40000 [==============================] - 50s 1ms/step - loss: 1.3764 - accuracy: 0.5143 - val_loss: 1.3527 - val_accuracy: 0.5107\n",
      "Epoch 3/20\n",
      "40000/40000 [==============================] - 45s 1ms/step - loss: 1.2437 - accuracy: 0.5612 - val_loss: 1.2262 - val_accuracy: 0.5671\n",
      "Epoch 4/20\n",
      "40000/40000 [==============================] - 45s 1ms/step - loss: 1.1554 - accuracy: 0.5933 - val_loss: 1.1578 - val_accuracy: 0.6027\n",
      "Epoch 5/20\n",
      "40000/40000 [==============================] - 45s 1ms/step - loss: 1.0867 - accuracy: 0.6215 - val_loss: 1.0996 - val_accuracy: 0.6174\n",
      "Epoch 6/20\n",
      "40000/40000 [==============================] - 45s 1ms/step - loss: 1.0246 - accuracy: 0.6426 - val_loss: 1.0830 - val_accuracy: 0.6242\n",
      "Epoch 7/20\n",
      "40000/40000 [==============================] - 46s 1ms/step - loss: 0.9695 - accuracy: 0.6620 - val_loss: 1.0275 - val_accuracy: 0.6460\n",
      "Epoch 8/20\n",
      "40000/40000 [==============================] - 49s 1ms/step - loss: 0.9298 - accuracy: 0.6750 - val_loss: 1.0330 - val_accuracy: 0.6418\n",
      "Epoch 9/20\n",
      "40000/40000 [==============================] - 47s 1ms/step - loss: 0.8894 - accuracy: 0.6909 - val_loss: 1.0312 - val_accuracy: 0.6502\n",
      "Epoch 10/20\n",
      "40000/40000 [==============================] - 46s 1ms/step - loss: 0.8506 - accuracy: 0.7036 - val_loss: 1.0872 - val_accuracy: 0.6486\n",
      "Epoch 11/20\n",
      "40000/40000 [==============================] - 45s 1ms/step - loss: 0.8135 - accuracy: 0.7174 - val_loss: 0.9947 - val_accuracy: 0.6679\n",
      "Epoch 12/20\n",
      "40000/40000 [==============================] - 45s 1ms/step - loss: 0.7842 - accuracy: 0.7312 - val_loss: 0.9891 - val_accuracy: 0.6694\n",
      "Epoch 13/20\n",
      "40000/40000 [==============================] - 45s 1ms/step - loss: 0.7579 - accuracy: 0.7391 - val_loss: 0.9799 - val_accuracy: 0.6791\n",
      "Epoch 14/20\n",
      "40000/40000 [==============================] - 47s 1ms/step - loss: 0.7306 - accuracy: 0.7454 - val_loss: 1.0141 - val_accuracy: 0.6657\n",
      "Epoch 15/20\n",
      "40000/40000 [==============================] - 49s 1ms/step - loss: 0.7077 - accuracy: 0.7532 - val_loss: 1.0076 - val_accuracy: 0.6738\n",
      "Epoch 16/20\n",
      "40000/40000 [==============================] - 45s 1ms/step - loss: 0.6825 - accuracy: 0.7635 - val_loss: 0.9857 - val_accuracy: 0.6745\n",
      "Epoch 17/20\n",
      "40000/40000 [==============================] - 61s 2ms/step - loss: 0.6539 - accuracy: 0.7755 - val_loss: 1.0204 - val_accuracy: 0.6820\n",
      "Epoch 18/20\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 0.6403 - accuracy: 0.7824 - val_loss: 1.1300 - val_accuracy: 0.6597\n",
      "Epoch 19/20\n",
      "40000/40000 [==============================] - 50s 1ms/step - loss: 0.6204 - accuracy: 0.7862 - val_loss: 1.0196 - val_accuracy: 0.6843\n",
      "Epoch 20/20\n",
      "40000/40000 [==============================] - 54s 1ms/step - loss: 0.5976 - accuracy: 0.7932 - val_loss: 1.0238 - val_accuracy: 0.6857\n",
      "10000/10000 [==============================] - 5s 547us/step\n",
      "Test score: 1.0393125385284423\n",
      "Test accuracy: 0.6769999861717224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3))`\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:117: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., epochs=20, verbose=1, steps_per_epoch=390)`\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "You must compile your model before using it.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-82f0cb79e53a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    115\u001b[0m history = model.fit_generator(datagen.flow(X_train, Y_train,\n\u001b[0;32m    116\u001b[0m batch_size=BATCH_SIZE), samples_per_epoch=X_train.shape[0],\n\u001b[1;32m--> 117\u001b[1;33m epochs=NB_EPOCH, verbose=VERBOSE)\n\u001b[0m\u001b[0;32m    118\u001b[0m score = model.evaluate(X_test, Y_test,\n\u001b[0;32m    119\u001b[0m batch_size=BATCH_SIZE, verbose=VERBOSE)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1732\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdo_validation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_test_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_make_train_function\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train_function'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 303\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'You must compile your model before using it.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    304\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_trainable_weights_consistency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: You must compile your model before using it."
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "NUM_TO_AUGMENT=5\n",
    "\n",
    "#load dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# augumenting\n",
    "print(\"Augmenting training set images...\")\n",
    "datagen = ImageDataGenerator(\n",
    "rotation_range=40,\n",
    "width_shift_range=0.2,\n",
    "height_shift_range=0.2,\n",
    "zoom_range=0.2,\n",
    "horizontal_flip=True,\n",
    "fill_mode='nearest')\n",
    "xtas, ytas = [], []\n",
    "for i in range(X_train.shape[0]):\n",
    "    num_aug = 0\n",
    "x = X_train[i] # (3, 32, 32)\n",
    "x = x.reshape((1,) + x.shape) # (1, 3, 32, 32)\n",
    "\n",
    "for x_aug in datagen.flow(x, batch_size=1,\n",
    "save_to_dir='preview', save_prefix='cifar', save_format='jpeg'):\n",
    "    if num_aug >= NUM_TO_AUGMENT:\n",
    "        break\n",
    "xtas.append(x_aug[0])\n",
    "num_aug += 1\n",
    "\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# CIFAR_10 is a set of 60K images 32x32 pixels on 3 channels\n",
    "IMG_CHANNELS = 3\n",
    "IMG_ROWS = 32\n",
    "IMG_COLS = 32\n",
    "\n",
    "#constant\n",
    "BATCH_SIZE = 128\n",
    "NB_EPOCH = 20\n",
    "NB_CLASSES = 10\n",
    "VERBOSE = 1\n",
    "VALIDATION_SPLIT = 0.2\n",
    "OPTIM = RMSprop()\n",
    "\n",
    "#load dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "\n",
    "# convert to categorical\n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
    "\n",
    "# float and normalization\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# network\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "# train\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIM,\n",
    "metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size=BATCH_SIZE,\n",
    "epochs=NB_EPOCH, validation_split=VALIDATION_SPLIT,\n",
    "verbose=VERBOSE)\n",
    "score = model.evaluate(X_test, Y_test,\n",
    "batch_size=BATCH_SIZE, verbose=VERBOSE)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "#save model\n",
    "model_json = model.to_json()\n",
    "open('cifar10_architecture.json', 'w').write(model_json)\n",
    "set\n",
    "model.save_weights('cifar10_weights.h5', overwrite=True)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#fit the dataget\n",
    "datagen.fit(X_train)\n",
    "# train\n",
    "history = model.fit_generator(datagen.flow(X_train, Y_train,\n",
    "batch_size=BATCH_SIZE), samples_per_epoch=X_train.shape[0],\n",
    "epochs=NB_EPOCH, verbose=VERBOSE)\n",
    "score = model.evaluate(X_test, Y_test,\n",
    "batch_size=BATCH_SIZE, verbose=VERBOSE)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CIFAR-10 dataset, like many others, may contain inherent biases related to class representation. If particular kinds of objects are underrepresented or overrepresented within classes, the model might develop biases leading to unfair predictions. Deep learning models are often criticized for their \"black box\" nature, making it difficult to understand and interpret their decision-making processes (Samek et al., 2017). This lack of transparency can be problematic, especially in applications where understanding the rationale behind a decision is vital. \n",
    "\n",
    "As such, the responsibility for the outcomes generated by AI models is with the developers of the technology. Ensuring that there are mechanisms in place to audit and review the model’s decisions is essential for maintaining accountability (Floridi et al., 2018). For this assignment, the CIFAR-10 dataset does not appear to contain PII, however the principles of data privacy should still be considered; if the training data were to include personal images, then that data would need to be obfuscated and/or consent would need to be obtained from data subjects, to comply with data protection regulations like GDPR in the EU(Goodman, 2016). If the trained model is deployed in an application where it interacts with user data, ensuring that this data is handled securely and used responsibly would be crucial to prevent unauthorized access to said data, and ensure compliance with privacy laws (Acquisti et al., 2015).\n",
    "\n",
    "References:\n",
    "\n",
    "Acquisti, A., Taylor, C. R., & Wagman, L. (2015). The Economics of Privacy. Journal of Economic Literature, 54(2), 442-492. https://doi.org/10.1257/jel.54.2.442\n",
    "\n",
    "Floridi, L., & Cowls, J. (2019). A Unified Framework of Five Principles for AI in Society. Harvard Data Science Review, 1(1). https://doi.org/10.1162/99608f92.8cd550d1\n",
    "\n",
    "Goodman, B. (2016). A Step Towards Accountable Algorithms? Algorithmic Discrimination and the European Union General Data Protection. 29th Conference on Neural Information Processing Systems (NIPS 2016), Workshop on Fairness, Accountability, and Transparency in Machine Learning (FAT/ML). https://arxiv.org/abs/1609.07187\n",
    "\n",
    "Samek, W., Wiegand, T., & Müller, K. R. (2017). Explainable Artificial Intelligence: Understanding, Visualizing and Interpreting Deep Learning Models. arXiv preprint arXiv:1708.08296. https://arxiv.org/abs/1708.08296"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
